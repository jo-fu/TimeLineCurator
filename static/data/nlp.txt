<?xml version="1.0" ?><DOC>
<BODY>
<TITLE>nlp</TITLE>
<DATE_TIME>2015-01-09</DATE_TIME>


<SENTENCES>

['  The history of machine translation dates back to <TIMEX2 VAL="16CENTURY">the seventeenth century</TIMEX2>, when philosophers such as Leibniz and Descartes put forward proposals for codes which would relate words between languages.', 'All of these proposals remained theoretical, and none resulted in the development of an actual machine.', 'The first patents for &quot;translating machines&quot; were applied for in the <TIMEX2 MOD="MID" VAL="1930DECADE">mid-1930s</TIMEX2>.', 'One proposal, by Georges Artsrouni was simply an automatic bilingual dictionary using paper tape.', 'The other proposal, by Peter Troyanskii, a Russian, was more detailed.', 'It included both the bilingual dictionary, and a method for dealing with grammatical roles between languages, based on Esperanto.', 'In <TIMEX2 VAL="1950">1950</TIMEX2>, Alan Turing published his famous article &quot;Computing Machinery and Intelligence&quot; which proposed what is <TIMEX2 VAL="PRESENT_REF">now</TIMEX2> called the Turing test as a criterion of intelligence.', 'This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge, sufficiently well that the judge is unable to distinguish reliably  on the basis of the conversational content alone  between the program and a real human.', 'In <TIMEX2 VAL="1957">1957</TIMEX2>, Noam Chomsky&#039;s Syntactic Structures revolutionized Linguistics with &#039;universal grammar&#039;, a rule based system of syntactic structures.', '[1] The Georgetown experiment in <TIMEX2 VAL="1954">1954</TIMEX2> involved fully automatic translation of more than sixty Russian sentences into English.', 'The authors claimed that within three or <TIMEX2 VAL="P5Y">five years</TIMEX2>, machine translation would be a solved problem.', '[2] However, real progress was much slower, and after the ALPAC report in <TIMEX2 VAL="1966">1966</TIMEX2>, which found that <TIMEX2 VAL="P10Y">ten years</TIMEX2> long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.', 'Little further research in machine translation was conducted until the late <TIMEX2 VAL="1980DECADE">1980&#039;s</TIMEX2>, when the first statistical machine translation systems were developed.', 'Some notably successful NLP systems developed in the <TIMEX2 VAL="1960DECADE">1960&#039;s</TIMEX2> were SHRDLU, a natural language system working in restricted &quot;blocks worlds&quot; with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between <TIMEX2 VAL="1964TO1966">1964 to 1966</TIMEX2>.', 'Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction.', 'When the &quot;patient&quot; exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to &quot;My head hurts&quot; with &quot;Why do you say your head hurts?&quot;.', 'In 1969 Roger Schank introduced the conceptual dependency theory for natural language understanding.', '[3] This model, partially influenced by the work of Sydney Lamb, was extensively used by Schank&#039;s students at Yale University, such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner.', 'In <TIMEX2 VAL="1970">1970</TIMEX2>, William A.', 'Woods introduced the augmented transition network (ATN) to represent natural language input.', '[4] Instead of phrase structure rules ATNs used an equivalent set of finite state automata that were called recursively.', 'ATNs and their more general format called &quot;generalized ATNs&quot; continued to be used for a number of years.During the 70&#039;s many programmers began to write &#039;conceptual ontologies&#039;, which structured real-world information into computer-understandable data.', 'Examples are MARGIE (Schank, <TIMEX2 VAL="1975">1975</TIMEX2>), SAM (Cullingford, <TIMEX2 VAL="1978">1978</TIMEX2>), PAM (Wilensky, <TIMEX2 VAL="1978">1978</TIMEX2>), TaleSpin (Meehan, <TIMEX2 VAL="1976">1976</TIMEX2>), QUALM (Lehnert, <TIMEX2 VAL="1977">1977</TIMEX2>), Politics (Carbonell, <TIMEX2 VAL="1979">1979</TIMEX2>), and Plot Units (Lehnert <TIMEX2 VAL="1981">1981</TIMEX2>).', 'During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.', 'Up to the <TIMEX2 VAL="1980DECADE">1980s</TIMEX2>, most NLP systems were based on complex sets of hand-written rules.', 'Starting in the late <TIMEX2 VAL="1980DECADE">1980s</TIMEX2>, however, there was a revolution in NLP with the introduction of machine learning algorithms for language processing.', 'This was due both to the steady increase in computational power resulting from Moore&#039;s Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g.', 'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.', '[5] Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.', 'Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.', 'The cache language models upon which many speech recognition systems <TIMEX2 VAL="PRESENT_REF">now</TIMEX2> rely are examples of such statistical models.', 'Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.', 'Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.', 'These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.', 'However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems.', 'As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.', 'Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.', 'Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.', 'Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.', 'However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results.  ']

</SENTENCES>